{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08994cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2fed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import albumentations as A\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from utils import read_image\n",
    "from utils import read_mask\n",
    "from utils import testing_model\n",
    "from utils import bfs\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img_shape = [512, 512]\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "transform = A.Compose([\n",
    "    A.Resize(512, 512),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "unet_path = 'trained_models/fold 1/model_resnet18_lovasz_05_05_120.pt'\n",
    "\n",
    "def attention_masks_for_images(unet_path, images_dir, dst_dir):\n",
    "    model = torch.load(unet_path, map_location=device)\n",
    "    model.eval()\n",
    "    \n",
    "    if not Path(dst_dir).exists():\n",
    "        os.mkdir(dst_dir)\n",
    "    \n",
    "    for image_path in tqdm(glob(images_dir + '/*')):\n",
    "        new_image = np.zeros((512, 512, 3))\n",
    "        image = read_image(image_path)\n",
    "        attention_mask, _ = testing_model(model, image)\n",
    "        for row in range(512):\n",
    "            for col in range(512):\n",
    "                new_image[row, col, :] = (255, 255, 255) if attention_mask[row, col] > 0 else image[row, col, :]\n",
    "        \n",
    "        cv2.imwrite(dst_dir + '/' + image_path.split('/')[-1], new_image)\n",
    "\n",
    "def convert_masks_to_yolo(images_path, masks_path, dst_path):\n",
    "    model = torch.load('type.pt', map_location=device)\n",
    "    if not Path(dst_path).exists():\n",
    "        os.mkdir(dst_path)\n",
    "        \n",
    "    for image_path in tqdm(images_path):\n",
    "        image = read_image(image_path)\n",
    "        mask = read_mask('/'.join(masks_path[0].split('/')[:-1]) + '/' + \n",
    "                         image_path.split('/')[-1])\n",
    "        timage = transform(image=image)['image']\n",
    "        timage = torch.tensor(timage).permute(2, 0, 1).view(1, 3, img_shape[0], img_shape[1])\n",
    "        timage = timage.to(device)\n",
    "        cls = -1\n",
    "        with torch.no_grad():\n",
    "            cls = model(timage).softmax(dim=1).argmax(dim=1).detach().cpu().numpy()[0]\n",
    "            \n",
    "        comps = bfs(mask)\n",
    "        bboxes = []\n",
    "        for comp in comps:\n",
    "            min_y, max_y, min_x, max_x = 10000000, -1, 10000000, -1\n",
    "            for node in comp[0]:\n",
    "                row, col = node // mask.shape[1], node % mask.shape[1]\n",
    "                min_y, min_x, max_y, max_x = min(min_y, row), min(min_x, col), max(max_y, row), max(max_x, col)\n",
    "            heigth, width = max_y - min_y - 2, max_x - min_x - 2\n",
    "            center_x, center_y = (max_x + min_x) // 2, (max_y + min_y) // 2\n",
    "            \n",
    "            assert (center_x - width / 2 >= 0.0), 'x- fucked'\n",
    "            assert (center_x + width / 2 <= mask.shape[1]), 'x+ fucked'\n",
    "            assert (center_y - heigth / 2 >= 0.0), 'y- fucked'\n",
    "            assert (center_y + heigth / 2 <= mask.shape[0]), 'y+ fucked'\n",
    "            \n",
    "            bboxes.append([center_x / mask.shape[1], center_y / mask.shape[0],\n",
    "                           width / mask.shape[1], heigth / mask.shape[0]])\n",
    "        \n",
    "        with open(os.path.join(dst_path, image_path.split('/')[-1][:-4] + '.txt'), 'w') as file:\n",
    "            for bbox in bboxes:\n",
    "                print(str(cls), ' '.join(list(map(str, bbox))), file=file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1554c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks_for_images(unet_path, 'new_images', 'attention_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325ef09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = glob('attention_images/*')\n",
    "masks_path = glob('new_masks/*')\n",
    "convert_masks_to_yolo(images_path, masks_path, 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3eb9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_yolo_dataset(images_dir, labels_dir, dst_dir):\n",
    "    if not Path(dst_dir).exists():\n",
    "        os.mkdir(dst_dir)\n",
    "        \n",
    "    images_path = list(sorted(glob(images_dir + '/*')))\n",
    "    labels_path = list(sorted(glob(labels_dir + '/*')))\n",
    "    \n",
    "    images_path_train, images_path_valid, labels_path_train, labels_path_valid = train_test_split(\n",
    "        images_path, labels_path, test_size=0.2, random_state=69\n",
    "    )\n",
    "    \n",
    "    if not Path(dst_dir + '/train').exists():\n",
    "        os.mkdir(dst_dir + '/train')\n",
    "    \n",
    "    if not Path(dst_dir + '/valid').exists():\n",
    "        os.mkdir(dst_dir + '/valid')\n",
    "        \n",
    "    if not Path(dst_dir + '/train/images').exists():\n",
    "        os.mkdir(dst_dir + '/train/images')\n",
    "    \n",
    "    if not Path(dst_dir + '/valid/images').exists():\n",
    "        os.mkdir(dst_dir + '/valid/images')\n",
    "    \n",
    "    if not Path(dst_dir + '/train/labels').exists():\n",
    "        os.mkdir(dst_dir + '/train/labels')\n",
    "    \n",
    "    if not Path(dst_dir + '/valid/labels').exists():\n",
    "        os.mkdir(dst_dir + '/valid/labels')\n",
    "        \n",
    "    for image_path, label_path in zip(images_path_train, labels_path_train):\n",
    "        os.system(f'cp {image_path} {dst_dir}/train/images/{image_path.split(\"/\")[-1]}')\n",
    "        os.system(f'cp {label_path} {dst_dir}/train/labels/{label_path.split(\"/\")[-1]}')\n",
    "        \n",
    "    for image_path, label_path in zip(images_path_valid, labels_path_valid):\n",
    "        os.system(f'cp {image_path} {dst_dir}/valid/images/{image_path.split(\"/\")[-1]}')\n",
    "        os.system(f'cp {label_path} {dst_dir}/valid/labels/{label_path.split(\"/\")[-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82bc13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_yolo_dataset('attention_images', 'labels', 'attention_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c5f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolo11n.pt')\n",
    "model.train(data='/home/anton/PycharmProjects/kaggle_competitions/severstal_aiijc/attention_ds/data.yaml',\n",
    "            epochs=100, batch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a739a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "# model.train(data='/home/anton/PycharmProjects/kaggle_competitions/severstal_aiijc/yolo_dataset_cs000_01/yolo_dataset_cs000_01/data.yaml',\n",
    "#             epochs=100, cos_lr=True, dropout=0.2, mixup=0.2, batch=8)\n",
    "# model.train(data='/home/anton/PycharmProjects/kaggle_competitions/severstal_aiijc/10k_dataset/10k_dataset/data.yaml',\n",
    "#             epochs=100, batch=8, single_cls=True)\n",
    "model.train(data='/home/anton/PycharmProjects/kaggle_competitions/severstal_aiijc/yolo_dataset_cs000_02/yolo_dataset_cs000_02/data.yaml',\n",
    "            epochs=100, batch=8, box=4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11779e00",
   "metadata": {},
   "source": [
    "# Швелера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f040762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "# model.train(data='/home/anton/PycharmProjects/kaggle_competitions/severstal_aiijc/yolo_dataset_cs000_01/yolo_dataset_cs000_01/data.yaml',\n",
    "#             epochs=100, cos_lr=True, dropout=0.2, mixup=0.2, batch=8)\n",
    "# model.train(data='/home/anton/PycharmProjects/kaggle_competitions/severstal_aiijc/10k_dataset/10k_dataset/data.yaml',\n",
    "#             epochs=100, batch=8, single_cls=True)\n",
    "model.train(data='/home/anton/PycharmProjects/kaggle_competitions/severstal_aiijc/channel_pipes_detection_aug/channel_pipes_detection_aug/data.yaml',\n",
    "            epochs=100, batch=8, box=14.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00789ae3",
   "metadata": {},
   "source": [
    "# Segmentation yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f9b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#segmentation yolo\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import albumentations as A\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import read_image\n",
    "from utils import read_mask\n",
    "from utils import bfs\n",
    "from utils import sort_points_clockwise\n",
    "\n",
    "transforms_val = A.Compose([\n",
    "    A.Resize(512, 512),\n",
    "    A.Normalize(mean=0.5, std=0.5)\n",
    "])\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = torch.load('type.pt', map_location=device)\n",
    "model.eval()\n",
    "\n",
    "if not Path('yolo_seg_dataset').exists():\n",
    "    os.mkdir('yolo_seg_dataset')\n",
    "    \n",
    "if not Path('yolo_seg_dataset/train').exists():\n",
    "    os.mkdir('yolo_seg_dataset/train')\n",
    "    \n",
    "if not Path('yolo_seg_dataset/test').exists():\n",
    "    os.mkdir('yolo_seg_dataset/test')\n",
    "    \n",
    "if not Path('yolo_seg_dataset/valid').exists():\n",
    "    os.mkdir('yolo_seg_dataset/valid')\n",
    "    \n",
    "if not Path('yolo_seg_dataset/train/images').exists():\n",
    "    os.mkdir('yolo_seg_dataset/train/images')\n",
    "    \n",
    "if not Path('yolo_seg_dataset/test/images').exists():\n",
    "    os.mkdir('yolo_seg_dataset/test/images')\n",
    "    \n",
    "if not Path('yolo_seg_dataset/valid/images').exists():\n",
    "    os.mkdir('yolo_seg_dataset/valid/images')\n",
    "    \n",
    "if not Path('yolo_seg_dataset/train/labels').exists():\n",
    "    os.mkdir('yolo_seg_dataset/train/labels')\n",
    "    \n",
    "if not Path('yolo_seg_dataset/test/labels').exists():\n",
    "    os.mkdir('yolo_seg_dataset/test/labels')\n",
    "    \n",
    "if not Path('yolo_seg_dataset/valid/labels').exists():\n",
    "    os.mkdir('yolo_seg_dataset/valid/labels')\n",
    "    \n",
    "images_path = list(sorted(glob('new_images/*')))\n",
    "masks_path = list(sorted(glob('new_masks/*')))\n",
    "\n",
    "\n",
    "images_path_train, images_path_test, masks_path_train, masks_path_test = train_test_split(\n",
    "    images_path, masks_path, test_size=0.25\n",
    ")\n",
    "\n",
    "images_path_test, images_path_val, masks_path_test, masks_path_val = train_test_split(\n",
    "    images_path_test, masks_path_test, test_size=0.4\n",
    ")\n",
    "def process_folder_for_yolo_seg(images_path, masks_path, mode):\n",
    "    i = 0\n",
    "    for image_path, mask_path in tqdm(zip(images_path, masks_path), total=len(images_path),\n",
    "                                     position=0, leave=True):\n",
    "        image = read_image(image_path)\n",
    "        mask = read_mask(mask_path)\n",
    "        comps = bfs(mask)\n",
    "        \n",
    "        assert len(comps) > 0, 'no comps wtf'\n",
    "\n",
    "        timage = transforms_val(image=image)['image']\n",
    "        timage = torch.tensor(timage).to(device)\n",
    "        timage = timage.permute(2, 0, 1)\n",
    "        timage = timage.view(1, *timage.shape)\n",
    "\n",
    "        cls = model(timage).softmax(dim=1).argmax(dim=1).detach().cpu().numpy()[0]\n",
    "        total = []\n",
    "        for comp in comps:\n",
    "            visited, degs = comp\n",
    "            \n",
    "            border_nodes = []\n",
    "            for node_idx in range(len(visited)):\n",
    "                if degs[node_idx] != 4:\n",
    "                    border_nodes.append(visited[node_idx])\n",
    "    \n",
    "            assert len(border_nodes) > 0, 'addd'\n",
    "            \n",
    "            coords = [((node % mask.shape[1]) / mask.shape[1], (node // mask.shape[1]) / mask.shape[0])\n",
    "                  for node in border_nodes]\n",
    "            \n",
    "            \n",
    "            assert len(coords) > 0, 'too little'\n",
    "            sorted_coords = sort_points_clockwise(coords)\n",
    "            sorted_coords = [sorted_coords[i] for i in range(0, len(sorted_coords), \n",
    "                                                    int(len(sorted_coords) ** (1/2)))]\n",
    "            \n",
    "            ss = []\n",
    "            for pair in sorted_coords:\n",
    "                ss.append(pair[0]), ss.append(pair[1])\n",
    "            total.append(ss)\n",
    "        \n",
    "        if i == 0:\n",
    "            bordered_mask = np.zeros((512, 512))\n",
    "            for tt in total:\n",
    "                for j in range(0, len(tt), 2):\n",
    "                    x, y = int(tt[j] * mask.shape[1]), int(tt[j + 1] * mask.shape[0])\n",
    "                    bordered_mask[y, x] = 255\n",
    "            cv2.imwrite('bordered_mask.png', bordered_mask)\n",
    "            i += 1\n",
    "        \n",
    "        with open(f'yolo_seg_dataset/{mode}/labels/' + mask_path.split('/')[-1][:-4] + '.txt', 'w') as file:\n",
    "            for pack in total:\n",
    "                print(str(cls), ' '.join(map(str, pack)), file=file)\n",
    "\n",
    "        cv2.imwrite(f'yolo_seg_dataset/{mode}/images/' + image_path.split('/')[-1], image)\n",
    "    \n",
    "process_folder_for_yolo_seg(images_path_train, masks_path_train, 'train')\n",
    "process_folder_for_yolo_seg(images_path_test, masks_path_test, 'test')\n",
    "process_folder_for_yolo_seg(images_path_val, masks_path_val, 'valid')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caaa9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolo11n-seg.pt')\n",
    "model.train(data='/home/anton/PycharmProjects/kaggle_competitions/severstal_aiijc/shvellers_seg/data.yaml', \n",
    "           epochs=200, batch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032e5daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=segment mode=train model=yolo11n-seg.pt data=/home/anton/PycharmProjects/kaggle_competitions/severstal_aiijc/ugols_seg/data.yaml epochs=200 imgsz=640 plots=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6148ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolo11n-seg.pt')\n",
    "model.train(data='/home/anton/PycharmProjects/kaggle_competitions/severstal_aiijc/shvellers_seg/data.yaml', \n",
    "           epochs=200, batch=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa8747",
   "metadata": {},
   "source": [
    "# One model for all types of pipes detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8883e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import albumentations as A\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from utils import read_image\n",
    "from utils import read_mask\n",
    "from utils import testing_model\n",
    "from utils import bfs\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ced12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ds_path = 'merged_dataset'\n",
    "if not Path(merged_ds_path).exists():\n",
    "    os.mkdir(merged_ds_path)\n",
    "    \n",
    "square_and_circles_ds_path = 'new_yolo_seg_dataset'\n",
    "ugols_ds_path = 'new_ugols_seg_aug'\n",
    "shvellers_ds_path = 'new_shvellers_seg_aug'\n",
    "\n",
    "sqc_images_path = list(sorted(glob(os.path.join(square_and_circles_ds_path, 'images') + '/*')))\n",
    "sqc_labels_path = list(sorted(glob(os.path.join(square_and_circles_ds_path, 'labels') + '/*')))\n",
    "\n",
    "sqc_images_path = [p for p in sqc_images_path if int(p.split('/')[-1].split('.')[0]) < 186]\n",
    "sqc_labels_path = [p for p in sqc_labels_path if int(p.split('/')[-1].split('.')[0]) < 186]\n",
    "sqc_images_path_add = [p for p in sqc_images_path if int(p.split('/')[-1].split('.')[0]) >= 186]\n",
    "sqc_labels_path_add = [p for p in sqc_labels_path if int(p.split('/')[-1].split('.')[0]) >= 186]\n",
    "# sqc_images_path = list(sorted(glob('original_images' + '/*')))\n",
    "# sqc_labels_path = list(sorted(glob(os.path.join(square_and_circles_ds_path, 'labels') + '/*')))\n",
    "# sqc_labels_path = [p for p in sqc_labels_path if 'original_images/' + p.split('/')[-1].split('.')[0] + '.png' in sqc_images_path]\n",
    "\n",
    "sqc_images_path_train, sqc_images_path_val, sqc_labels_path_train, sqc_labels_path_val = train_test_split(\n",
    "    sqc_images_path, sqc_labels_path, test_size=0.1, random_state=69\n",
    ")\n",
    "print(len(sqc_images_path_train))\n",
    "\n",
    "if not Path(os.path.join(merged_ds_path, 'train')).exists():\n",
    "    os.mkdir(os.path.join(merged_ds_path, 'train'))\n",
    "    \n",
    "if not Path(os.path.join(merged_ds_path, 'valid')).exists():\n",
    "    os.mkdir(os.path.join(merged_ds_path, 'valid'))\n",
    "    \n",
    "if not Path(os.path.join(merged_ds_path, 'train', 'images')).exists():\n",
    "    os.mkdir(os.path.join(merged_ds_path, 'train', 'images'))\n",
    "    \n",
    "if not Path(os.path.join(merged_ds_path, 'valid', 'images')).exists():\n",
    "    os.mkdir(os.path.join(merged_ds_path, 'valid', 'images'))\n",
    "    \n",
    "if not Path(os.path.join(merged_ds_path, 'train', 'labels')).exists():\n",
    "    os.mkdir(os.path.join(merged_ds_path, 'train', 'labels'))\n",
    "    \n",
    "if not Path(os.path.join(merged_ds_path, 'valid', 'labels')).exists():\n",
    "    os.mkdir(os.path.join(merged_ds_path, 'valid', 'labels'))\n",
    "    \n",
    "for image_path, label_path in zip(sqc_images_path_train, sqc_labels_path_train):\n",
    "    os.system(f\"cp {image_path} {merged_ds_path + '/train/images/' + image_path.split('/')[-1]} \")\n",
    "    os.system(f\"cp {label_path} {merged_ds_path + '/train/labels/' + label_path.split('/')[-1].split('.')[0] + '.txt'} \")\n",
    "    \n",
    "for image_path, label_path in zip(sqc_images_path_val, sqc_labels_path_val):\n",
    "    os.system(f\"cp {image_path} {merged_ds_path + '/valid/images/' + image_path.split('/')[-1]} \")\n",
    "    os.system(f\"cp {label_path} {merged_ds_path + '/valid/labels/' + label_path.split('/')[-1].split('.')[0] + '.txt'} \")\n",
    "    \n",
    "for image_path, label_path in zip(sqc_images_path_add, sqc_labels_path_add):\n",
    "    os.system(f\"cp {image_path} {merged_ds_path + '/train/images/' + image_path.split('/')[-1]} \")\n",
    "    os.system(f\"cp {label_path} {merged_ds_path + '/train/labels/' + label_path.split('/')[-1].split('.')[0] + '.txt'} \")\n",
    "    \n",
    "shv_images_path_train = list(sorted(glob(os.path.join(shvellers_ds_path, 'train', 'images') + '/*')))\n",
    "shv_images_path_val = list(sorted(glob(os.path.join(shvellers_ds_path, 'valid', 'images') + '/*')))\n",
    "shv_labels_path_train = list(sorted(glob(os.path.join(shvellers_ds_path, 'train', 'labels') + '/*')))\n",
    "shv_labels_path_val = list(sorted(glob(os.path.join(shvellers_ds_path, 'valid', 'labels') + '/*')))\n",
    "\n",
    "\n",
    "for image_path, label_path in zip(shv_images_path_train, shv_labels_path_train):\n",
    "    os.system(f\"cp {image_path} {merged_ds_path + '/train/images/' + image_path.split('/')[-1]} \")\n",
    "    os.system(f\"cp {label_path} {merged_ds_path + '/train/labels/' + label_path.split('/')[-1].split('.')[0] + '.txt'} \")\n",
    "    \n",
    "for image_path, label_path in zip(shv_images_path_val, shv_labels_path_val):\n",
    "    os.system(f\"cp {image_path} {merged_ds_path + '/valid/images/' + image_path.split('/')[-1]} \")\n",
    "    os.system(f\"cp {label_path} {merged_ds_path + '/valid/labels/' + label_path.split('/')[-1].split('.')[0] + '.txt'} \")\n",
    "    \n",
    "ugols_images_path_train = list(sorted(glob(os.path.join(ugols_ds_path, 'train', 'images') + '/*')))\n",
    "ugols_images_path_val = list(sorted(glob(os.path.join(ugols_ds_path, 'valid', 'images') + '/*')))\n",
    "ugols_labels_path_train = list(sorted(glob(os.path.join(ugols_ds_path, 'train', 'labels') + '/*')))\n",
    "ugols_labels_path_val = list(sorted(glob(os.path.join(ugols_ds_path, 'valid', 'labels') + '/*')))\n",
    "print()\n",
    "\n",
    "for image_path, label_path in zip(ugols_images_path_train, ugols_labels_path_train):\n",
    "    os.system(f\"cp {image_path} {merged_ds_path + '/train/images/' + 'cc' + image_path.split('/')[-1]} \")\n",
    "    os.system(f\"cp {label_path} {merged_ds_path + '/train/labels/' + 'cc' + label_path.split('/')[-1].split('.')[0] + '.txt'} \")\n",
    "    \n",
    "for image_path, label_path in zip(ugols_images_path_val, ugols_labels_path_val):\n",
    "    os.system(f\"cp {image_path} {merged_ds_path + '/valid/images/' + 'cc' + image_path.split('/')[-1]} \")\n",
    "    os.system(f\"cp {label_path} {merged_ds_path + '/valid/labels/' + 'cc' + label_path.split('/')[-1].split('.')[0] + '.txt'} \")\n",
    "    \n",
    "os.system(f\"cp data.yaml {merged_ds_path}/data.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c20a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolo11n.pt')\n",
    "model.train(data='/home/anton/PycharmProjects/kaggle_competitions/severstal_aiijc/merged_dataset/data.yaml', \n",
    "           epochs=200, batch=16, box=15.0, cls=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038f79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(format='torchscript')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c41b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch_script_model = torch.jit.load('runs/detect/train39/weights/best.torchscript')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e612d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch_script_model('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
